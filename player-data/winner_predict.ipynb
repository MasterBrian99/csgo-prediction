{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Parameters of the call\n",
    "def params(argument):\n",
    "    if argument == 'team_1':\n",
    "        return 'Natus Vincere'\n",
    "    elif argument == 'team_2':\n",
    "        return 'fnatic'\n",
    "    elif argument == '_map':\n",
    "        return 'Mirage'\n",
    "    elif argument == 'rank_1':\n",
    "        return 867\n",
    "    elif argument == 'rank_2':\n",
    "        return 583\n",
    "    raise NameError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "print('Importing data...')\n",
    "dataset = pd.read_csv('../data-collecter-js/csv/results.csv')\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "_2019 = datetime.date(2019, 1, 1)\n",
    "_2019 = pd.to_datetime(_2019)\n",
    "dataset = dataset.loc[dataset['date'] >= _2019]\n",
    "dataset_p1 = dataset.loc[dataset['team_1'] == params('team_1')]\n",
    "dataset_p2 = dataset.loc[dataset['team_2'] == params('team_1')]\n",
    "dataset_p3 = dataset.loc[(dataset['team_1'] == params('team_2')) & (dataset['team_2'] != params('team_1'))]\n",
    "dataset_p4 = dataset.loc[(dataset['team_2'] == params('team_2')) & (dataset['team_1'] != params('team_1'))]\n",
    "dataset = pd.concat([dataset_p1, dataset_p2, dataset_p3, dataset_p4])\n",
    "X = dataset.iloc[:, [1, 2, 3, 14, 15]].values\n",
    "y = dataset.iloc[:, 6].values\n",
    "print('Success!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Start function\n",
    "def choice():\n",
    "    print('Starting to learn...')\n",
    "    user_choice = '1'\n",
    "    if user_choice == '1':\n",
    "        learn()\n",
    "    elif user_choice == '2':\n",
    "        print('Programm finished.')\n",
    "    else:\n",
    "        print('\\nYou probably pressed the wrong button, try again!')\n",
    "        choice()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Learning accuracy function, %\n",
    "def accuracy():\n",
    "    global X\n",
    "    global y\n",
    "    print('Evaluating accuracy...')\n",
    "    # Encoding categorical data\n",
    "    onehotencoder = OneHotEncoder()\n",
    "    X_new = onehotencoder.fit_transform(X[:, 0:2]).toarray()\n",
    "    X_new = X_new[:, 1:]\n",
    "    X = X[:, [3, 4]]\n",
    "    X = np.concatenate((X, X_new), axis=1)\n",
    "\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    # Fitting XGBoost\n",
    "    classifier = XGBClassifier(n_estimators=500, learning_rate=0.00001,\n",
    "                               max_depth=7, subsample=0.8, colsample_bytree=0.8, gamma=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_sum = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1]\n",
    "    avg_acc = (cm[0][0] + cm[1][1]) / cm_sum * 100\n",
    "    # Returning average accuracy of the algorithm\n",
    "    return avg_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Main predict function\n",
    "def learn():\n",
    "    global X\n",
    "    global y\n",
    "    team_1 = params('team_1')\n",
    "    team_2 = params('team_2')\n",
    "    rank_1 = params('rank_1')\n",
    "    rank_2 = params('rank_2')\n",
    "    _map = params('_map')\n",
    "    X_test = np.array([[team_1, team_2, _map, rank_1, rank_2]])\n",
    "    # Encoding categorical data\n",
    "    print('Encoding data...')\n",
    "    onehotencoder = OneHotEncoder()\n",
    "    X_new_transformed = onehotencoder.fit_transform(X[:, 0:2]).toarray()\n",
    "    X_new_transformed = X_new_transformed[:, 1:]\n",
    "    X_transformed = X[:, [3, 4]]\n",
    "    X_transformed = np.concatenate((X_transformed, X_new_transformed), axis=1)\n",
    "    X_test_new_transformed = onehotencoder.transform(X_test[:, 0:2]).toarray()\n",
    "    X_test_new_transformed = X_test_new_transformed[:, 1:]\n",
    "    X_test_transformed = X_test[:, [3, 4]]\n",
    "    X_test_transformed = np.concatenate((X_test_transformed, X_test_new_transformed), axis=1)\n",
    "    print('Success!')\n",
    "    print('Splitting the dataset...')\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train, X_test_old, y_train, y_test_old = train_test_split(X_transformed, y, test_size=1)\n",
    "    print('Success!')\n",
    "    print('Fitting XGBoost...')\n",
    "    # Fitting XGBoost\n",
    "    classifier = XGBClassifier(n_estimators=500, learning_rate=0.00001,\n",
    "                               max_depth=7, subsample=0.8, colsample_bytree=0.8, gamma=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print('Success!')\n",
    "    print('Predicting')\n",
    "    # Predicting\n",
    "    y_pred = classifier.predict(X_test_transformed)\n",
    "    print('Success!')\n",
    "    accuracy_final = accuracy()\n",
    "    # Predicting the Test set results\n",
    "    print(f'Accuracy of the algorithm: {accuracy_final}%')\n",
    "    if y_pred == 2:\n",
    "        print(f'Algorithm predicts that {team_1} will win {team_2}.')\n",
    "    elif y_pred == 1:\n",
    "        print(f'Algorithm predicts that {team_2} will win {team_1}.')\n",
    "    else:\n",
    "        print('An unexpected error has occured.')\n",
    "    print('Programm finished.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to learn...\n",
      "Encoding data...\n",
      "Success!\n",
      "Splitting the dataset...\n",
      "Success!\n",
      "Fitting XGBoost...\n",
      "[21:18:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/.conda/envs/workspace/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Predicting\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[21:18:34] ../src/c_api/../data/array_interface.h:357: Unicode-3 is not supported.\nStack trace:\n  [bt] (0) /home/brian/.conda/envs/workspace/lib/libxgboost.so(+0x9c2d5) [0x7fd274e9c2d5]\n  [bt] (1) /home/brian/.conda/envs/workspace/lib/libxgboost.so(+0xac3c6) [0x7fd274eac3c6]\n  [bt] (2) /home/brian/.conda/envs/workspace/lib/libxgboost.so(XGBoosterPredictFromDense+0x11d) [0x7fd274eaef0d]\n  [bt] (3) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd2b58e29dd]\n  [bt] (4) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd2b58e2067]\n  [bt] (5) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x13a25) [0x7fd2b54f2a25]\n  [bt] (6) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x1049f) [0x7fd2b54ef49f]\n  [bt] (7) /home/brian/.conda/envs/workspace/bin/python(_PyObject_MakeTpCall+0x15e) [0x55e0bb32b52e]\n  [bt] (8) /home/brian/.conda/envs/workspace/bin/python(_PyEval_EvalFrameDefault+0x4ce5) [0x55e0bb3ced75]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mXGBoostError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mchoice\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m user_choice \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m user_choice \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m user_choice \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProgramm finished.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36mlearn\u001B[0;34m()\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicting\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Predicting\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_transformed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSuccess!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     37\u001B[0m accuracy_final \u001B[38;5;241m=\u001B[39m accuracy()\n",
      "File \u001B[0;32m~/.conda/envs/workspace/lib/python3.10/site-packages/xgboost/sklearn.py:1284\u001B[0m, in \u001B[0;36mXGBClassifier.predict\u001B[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1277\u001B[0m     X: array_like,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1282\u001B[0m     iteration_range: Optional[Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1283\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m-> 1284\u001B[0m     class_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mntree_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mntree_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[43m        \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1291\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_margin:\n\u001B[1;32m   1293\u001B[0m         \u001B[38;5;66;03m# If output_margin is active, simply return the scores\u001B[39;00m\n\u001B[1;32m   1294\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m class_probs\n",
      "File \u001B[0;32m~/.conda/envs/workspace/lib/python3.10/site-packages/xgboost/sklearn.py:881\u001B[0m, in \u001B[0;36mXGBModel.predict\u001B[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_can_use_inplace_predict():\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 881\u001B[0m         predts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace_predict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpredict_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmargin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    889\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m _is_cupy_array(predts):\n\u001B[1;32m    890\u001B[0m             \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m     \u001B[38;5;66;03m# pylint: disable=import-error\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/workspace/lib/python3.10/site-packages/xgboost/core.py:2034\u001B[0m, in \u001B[0;36mBooster.inplace_predict\u001B[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[1;32m   2032\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _ensure_np_dtype\n\u001B[1;32m   2033\u001B[0m     data, _ \u001B[38;5;241m=\u001B[39m _ensure_np_dtype(data, data\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m-> 2034\u001B[0m     \u001B[43m_check_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2035\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterPredictFromDense\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2036\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2037\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_array_interface\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2038\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfrom_pystr_to_cstr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2039\u001B[0m \u001B[43m            \u001B[49m\u001B[43mp_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2040\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2041\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdims\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2042\u001B[0m \u001B[43m            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2043\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2044\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2045\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _prediction_output(shape, dims, preds, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, scipy\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39mcsr_matrix):\n",
      "File \u001B[0;32m~/.conda/envs/workspace/lib/python3.10/site-packages/xgboost/core.py:218\u001B[0m, in \u001B[0;36m_check_call\u001B[0;34m(ret)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"Check the return value of C API call\u001B[39;00m\n\u001B[1;32m    208\u001B[0m \n\u001B[1;32m    209\u001B[0m \u001B[38;5;124;03mThis function will raise exception when error occurs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;124;03m    return value from API calls\u001B[39;00m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m XGBoostError(py_str(_LIB\u001B[38;5;241m.\u001B[39mXGBGetLastError()))\n",
      "\u001B[0;31mXGBoostError\u001B[0m: [21:18:34] ../src/c_api/../data/array_interface.h:357: Unicode-3 is not supported.\nStack trace:\n  [bt] (0) /home/brian/.conda/envs/workspace/lib/libxgboost.so(+0x9c2d5) [0x7fd274e9c2d5]\n  [bt] (1) /home/brian/.conda/envs/workspace/lib/libxgboost.so(+0xac3c6) [0x7fd274eac3c6]\n  [bt] (2) /home/brian/.conda/envs/workspace/lib/libxgboost.so(XGBoosterPredictFromDense+0x11d) [0x7fd274eaef0d]\n  [bt] (3) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd2b58e29dd]\n  [bt] (4) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd2b58e2067]\n  [bt] (5) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x13a25) [0x7fd2b54f2a25]\n  [bt] (6) /home/brian/.conda/envs/workspace/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x1049f) [0x7fd2b54ef49f]\n  [bt] (7) /home/brian/.conda/envs/workspace/bin/python(_PyObject_MakeTpCall+0x15e) [0x55e0bb32b52e]\n  [bt] (8) /home/brian/.conda/envs/workspace/bin/python(_PyEval_EvalFrameDefault+0x4ce5) [0x55e0bb3ced75]\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "choice()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}